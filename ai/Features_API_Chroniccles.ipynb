{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9KRblyc1Akp",
        "outputId": "7ddb3079-72af-46e2-caa7-6160324c2a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-groq\n",
            "  Downloading llama_index_llms_groq-0.1.4-py3-none-any.whl (2.9 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-groq) (0.10.43.post1)\n",
            "Collecting llama-index-llms-openai-like<0.2.0,>=0.1.3 (from llama-index-llms-groq)\n",
            "  Downloading llama_index_llms_openai_like-0.1.3-py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.33.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.12.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.14.1)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.1.22)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (4.41.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.7.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.23.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (24.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.4.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.16.0)\n",
            "Installing collected packages: llama-index-llms-openai-like, llama-index-llms-groq\n",
            "Successfully installed llama-index-llms-groq-0.1.4 llama-index-llms-openai-like-0.1.3\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting groq\n",
            "  Downloading groq-0.8.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.18.4)\n",
            "Installing collected packages: groq\n",
            "Successfully installed groq-0.8.0\n",
            "Collecting socketify\n",
            "  Downloading socketify-0.0.27.tar.gz (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from socketify) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=58.1.0 in /usr/local/lib/python3.10/dist-packages (from socketify) (67.7.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->socketify) (2.22)\n",
            "Building wheels for collected packages: socketify\n",
            "  Building wheel for socketify (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for socketify: filename=socketify-0.0.27-cp310-cp310-linux_x86_64.whl size=5524874 sha256=6d42abc13f134451564834175ed917f3285fd51af594d06d12ddda9a438e1be2\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/6e/17/6f141ec81dd7b8af0ce5c350ec5f110fa301ad0c5ad650b3cd\n",
            "Successfully built socketify\n",
            "Installing collected packages: pyngrok, socketify\n",
            "Successfully installed pyngrok-7.1.6 socketify-0.0.27\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing LLAMA, Groq\n",
        "!pip install -q llama-index==0.10.14\n",
        "!pip install llama-index-llms-groq\n",
        "from llama_index.llms.groq import Groq\n",
        "!pip install -q gradio\n",
        "import gradio as gr\n",
        "import markdown\n",
        "import time\n",
        "!pip install groq\n",
        "!pip install socketify pyngrok\n",
        "!pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBrKgkYw1CEF",
        "outputId": "54f267b9-30da-4b93-f591-fe91b64ce782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.111.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.37.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.1)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.9)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (5.10.0)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.10.3)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.4)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (11.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install fastapi uvicorn pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tejMSNktOqSa",
        "outputId": "cb1e28ca-1ca4-4fe7-a691-4ecaa0bffec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rake-nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from rake-nltk) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.66.4)\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# First, let's install the necessary package: rake-nltk - similarity document\n",
        "!pip install rake-nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-coL92MTqYV",
        "outputId": "96e58da2-e07e-42e3-b435-894cf66cbb5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [212]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok tunnel \"public_url\" -> \"http://127.0.0.1:8000\"\n",
            "Public URL: NgrokTunnel: \"https://select-visually-ram.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "INFO:     103.67.78.86:0 - \"POST /v1/grading-similarity-document HTTP/1.1\" 200 OK\n",
            "INFO:     103.67.78.86:0 - \"POST /v1/grading-similarity-document HTTP/1.1\" 200 OK\n",
            "INFO:     103.67.78.86:0 - \"POST /v1/grading-recommendation HTTP/1.1\" 200 OK\n",
            "INFO:     103.67.78.86:0 - \"POST /v1/grading-recommendation HTTP/1.1\" 200 OK\n",
            "INFO:     103.67.78.86:0 - \"POST /v1/grading-recommendation HTTP/1.1\" 200 OK\n",
            "INFO:     103.67.78.86:0 - \"POST /v1/grading-recommendation HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "# Import Depedencies\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from rake_nltk import Rake\n",
        "from nltk.corpus import stopwords\n",
        "import nest_asyncio\n",
        "from fastapi import FastAPI, HTTPException, Form\n",
        "from pydantic import BaseModel\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.llms.groq import Groq\n",
        "import re\n",
        "from typing import List\n",
        "import random\n",
        "nest_asyncio.apply()\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Similarity Texts\n",
        "# RAKE - TF-IDF - Cosine Similarity\n",
        "# Define a Pydantic model for the input data\n",
        "class Story(BaseModel):\n",
        "    id_story: str\n",
        "    orientation: str\n",
        "    complication: str\n",
        "    resolution: str\n",
        "    reorientation: str\n",
        "    kode_kelompok: str\n",
        "\n",
        "class Stories(BaseModel):\n",
        "    lists: List[Story]\n",
        "\n",
        "# Function to calculate similarity using RAKE and TF-IDF\n",
        "def texts_similarity_with_rake(stories):\n",
        "    # Initialize RAKE using NLTK's stopwords\n",
        "    rake = Rake(stopwords=stopwords.words('english'))\n",
        "    prepared_texts = []\n",
        "\n",
        "    # Extract and prepare key phrases for all texts\n",
        "    for story in stories:\n",
        "        combined_text = f\"{story.orientation} {story.complication} {story.resolution} {story.reorientation}\"\n",
        "        rake.extract_keywords_from_text(combined_text)\n",
        "        key_phrases = rake.get_ranked_phrases()\n",
        "        prepared_text = \" \".join(key_phrases)\n",
        "        prepared_texts.append(prepared_text)\n",
        "\n",
        "    # Create TF-IDF vectors for all prepared texts\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(prepared_texts)\n",
        "\n",
        "    # Calculate the cosine similarity matrix\n",
        "    similarity_matrix = cosine_similarity(vectors)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "# Define the API endpoint\n",
        "@app.post(\"/v1/grading-similarity-document\")\n",
        "async def calculate_similarity(stories: Stories):\n",
        "    similarity_matrix = texts_similarity_with_rake(stories.lists)\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(stories.lists)):\n",
        "        for j in range(i + 1, len(stories.lists)):\n",
        "            result = {\n",
        "                \"id_story_1\": stories.lists[i].id_story,\n",
        "                \"orientation_1\": stories.lists[i].orientation,\n",
        "                \"complication_1\": stories.lists[i].complication,\n",
        "                \"resolution_1\": stories.lists[i].resolution,\n",
        "                \"reorientation_1\": stories.lists[i].reorientation,\n",
        "                \"kode_kelompok_1\": stories.lists[i].kode_kelompok,\n",
        "                \"id_story_2\": stories.lists[j].id_story,\n",
        "                \"orientation_2\": stories.lists[j].orientation,\n",
        "                \"complication_2\": stories.lists[j].complication,\n",
        "                \"resolution_2\": stories.lists[j].resolution,\n",
        "                \"reorientation_2\": stories.lists[j].reorientation,\n",
        "                \"kode_kelompok_2\": stories.lists[j].kode_kelompok,\n",
        "                \"similarity_score\": similarity_matrix[i][j]\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "    return {\"similarity_results\": results}\n",
        "\n",
        "# QUIZ\n",
        "class Quiz(BaseModel):\n",
        "    document: str\n",
        "    question: str\n",
        "    choices: list\n",
        "    correct_field: str\n",
        "\n",
        "class Answer(BaseModel):\n",
        "    quiz: list[Quiz]\n",
        "    user_answers: list[int]\n",
        "\n",
        "class DocumentData(BaseModel):\n",
        "    data: dict\n",
        "\n",
        "# Create a quiz from the JSON data\n",
        "def create_quiz(data, num_quizzes=5):\n",
        "    fields = [\"Orientasi\", \"Complication\", \"Resolution\", \"Reorientation\", \"Recomplication\"]\n",
        "    documents = list(data.keys())\n",
        "    quizzes = []\n",
        "\n",
        "    for _ in range(num_quizzes):\n",
        "        selected_doc = random.choice(documents)\n",
        "        selected_field = random.choice(fields)\n",
        "        correct_answer = data[selected_doc][selected_field]\n",
        "        quiz = {\n",
        "            'document': selected_doc,\n",
        "            'question': correct_answer,\n",
        "            'choices': fields,\n",
        "            'correct_field': selected_field\n",
        "        }\n",
        "        quizzes.append(quiz)\n",
        "\n",
        "    return quizzes\n",
        "\n",
        "# Evaluate the quiz\n",
        "def evaluate_quiz(quiz, user_answers):\n",
        "    score = 0\n",
        "    total = len(quiz)\n",
        "\n",
        "    evaluation_result = []\n",
        "    for q, user_choice_index in zip(quiz, user_answers):\n",
        "        user_answer = q.choices[user_choice_index]\n",
        "        correct_answer = q.correct_field\n",
        "        is_correct = user_answer == correct_answer\n",
        "        if is_correct:\n",
        "            score += 1\n",
        "        evaluation_result.append({\n",
        "            'question': q.question,\n",
        "            'user_answer': user_answer,\n",
        "            'correct_answer': correct_answer,\n",
        "            'is_correct': is_correct\n",
        "        })\n",
        "\n",
        "    return score, total, evaluation_result\n",
        "\n",
        "# MAKE QUIZ\n",
        "@app.post(\"/v1/make-quiz\")\n",
        "def make_quiz(document_data: DocumentData, num_quizzes: int = 5):\n",
        "    data = document_data.data\n",
        "    quizzes = create_quiz(data, num_quizzes)\n",
        "    return {\"quizzes\": quizzes}\n",
        "\n",
        "# CHECK ANSWERS\n",
        "@app.post(\"/v1/check-answer\")\n",
        "def check_answer(answer: Answer):\n",
        "    score, total, evaluation_result = evaluate_quiz(answer.quiz, answer.user_answers)\n",
        "    text_total_score = f\"{score}/{total}\"\n",
        "    grade_score = score / total * 100\n",
        "    return {\n",
        "        \"total_score\": text_total_score,\n",
        "        \"grade_score\": grade_score,\n",
        "        \"evaluation_result\": evaluation_result\n",
        "    }\n",
        "\n",
        "# LLM Groq Update\n",
        "# Define the request model for input text\n",
        "class LLMRequest(BaseModel):\n",
        "    input_text: str\n",
        "\n",
        "# LLM RECOMENDATION SCORE\n",
        "\n",
        "# Api of grading\n",
        "@app.post(\"/v1/grading-recommendation\")\n",
        "async def process_text(request: LLMRequest):\n",
        "    llm = Groq(model=\"mixtral-8x7b-32768\", api_key=\"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\")\n",
        "\n",
        "    prompt = \"\"\"\n",
        "    As a specialized assistant in teaching and evaluating narrative text structure, your task entails assessing the provided narrative based on Orientation, Complication, Resolution, and Reorientation,\n",
        "    devoid of extensive preamble. Each segment will be scrutinized for quality, with specific examples provided, and at least five detailed suggestions for improvement offered. Grammatical or syntactical\n",
        "    errors will be identified, along with clear recommendations for correction. The significance of each mistake will be highlighted, elucidating how rectifying them could enhance the overall text quality.\n",
        "    The evaluation will culminate in assigning a final grade, within even numbers ranging between 75-100, based on the Minimum Completeness Criteria (KKM), supported by objective justifications.\n",
        "    The entire process will adhere to academic standards.\\nFinal Grade: [Score]\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        ChatMessage(\n",
        "            role=\"system\", content=prompt,\n",
        "            temperature=0.8,\n",
        "            max_tokens=24576,\n",
        "            top_p=1,\n",
        "        ),\n",
        "        ChatMessage(role=\"user\", content=request.input_text),\n",
        "    ]\n",
        "\n",
        "    resp = llm.chat(messages)\n",
        "\n",
        "    # Extracting the Final Grade using regex\n",
        "    content = resp.message.content\n",
        "    final_grade_match = re.search(r'Final Grade:\\s*(\\d+)', content)\n",
        "    if final_grade_match:\n",
        "        final_grade = final_grade_match.group(1)\n",
        "\n",
        "    # Removing the original \"Final Grade\" line from the content\n",
        "    resp.message.content = re.sub(r'Final Grade:\\s*\\d+\\n\\n', '', content)\n",
        "\n",
        "\n",
        "    # Assuming `resp` contains the response from the LLM in the format you expect\n",
        "    # You might need to adjust the below line based on the actual structure of `resp`\n",
        "    response = {\"message\": \"Processed text\", \"result\": resp.message.content, \"final_grade\":final_grade}\n",
        "    return response\n",
        "\n",
        "# Start the Server\n",
        "def start_ngrok():\n",
        "    url = ngrok.connect(8000, hostname=\"select-visually-ram.ngrok-free.app\")\n",
        "    print('ngrok tunnel \"public_url\" -> \"http://127.0.0.1:8000\"')\n",
        "    print(f\"Public URL: {url}\")\n",
        "\n",
        "# Set the environtment\n",
        "if __name__ == \"__main__\":\n",
        "    ngrok.set_auth_token(\"2hHxvO2eUfWGhtbxk8HLVA76943_6Jqg3i743gk3b93LFSBnQ\")\n",
        "    start_ngrok()\n",
        "    uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDN_qQf3WrI"
      },
      "source": [
        "# Testing\n",
        "Resource Independently Testing Features:\n",
        "\n",
        "RAKE:\n",
        "https://colab.research.google.com/drive/1utMUHccXoQZqnRo3r9oUdHj8D-SnaFV7#scrollTo=VB9mOqGvVxt_\n",
        "\n",
        "Groq-chat:\n",
        "https://colab.research.google.com/drive/1DZ0ZWDf4LqznrfeYKuNU1t9AdXFAxMLz?usp=sharing\n",
        "\n",
        "Make-Quiz-Check-Answer\n",
        "https://colab.research.google.com/drive/1v8Z8a0ov4C5S7MPo7RJ4tvMDlYFCIbPS?usp=sharing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nsJ8aFS6-bo"
      },
      "outputs": [],
      "source": [
        "# This is testing of the\n",
        "# def process_text(input_text):\n",
        "#     llm = Groq(model=\"mixtral-8x7b-32768\", api_key=\"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\")\n",
        "\n",
        "#     prompt = \"\"\"\n",
        "#     As a specialized assistant in teaching and evaluating narrative text structure, your task entails assessing the provided narrative based on Orientation, Complication, Resolution, and Reorientation,\n",
        "#     devoid of extensive preamble. Each segment will be scrutinized for quality, with specific examples provided, and at least five detailed suggestions for improvement offered. Grammatical or syntactical\n",
        "#     errors will be identified, along with clear recommendations for correction. The significance of each mistake will be highlighted, elucidating how rectifying them could enhance the overall text quality.\n",
        "#     The evaluation will culminate in assigning a final grade, within even numbers ranging between 75-100, based on the Minimum Completeness Criteria (KKM), supported by objective justifications.\n",
        "#     The entire process will adhere to academic standards.\\nFinal Grade: [Score]\n",
        "#     \"\"\"\n",
        "\n",
        "#     messages = [\n",
        "#         ChatMessage(\n",
        "#             role=\"system\", content=prompt,\n",
        "#             temperature=0.8,\n",
        "#             max_tokens=24576,\n",
        "#             top_p=1,\n",
        "#         ),\n",
        "#         ChatMessage(role=\"user\", content=input_text),\n",
        "#     ]\n",
        "\n",
        "#     resp = llm.chat(messages)\n",
        "#     # Assuming `resp` contains the response from the LLM in the format you expect\n",
        "#     # You might need to adjust the below line based on the actual structure of `resp`\n",
        "#     response = {\"message\": \"Processed text\", \"result\": resp}\n",
        "#     return response\n",
        "\n",
        "# input_text = \"\"\"\n",
        "# Once upon a time, in the vast and endless sky, there lived a joyful cloud named Nimbus. Nimbus enjoyed a unique friendship with both the Sun, who shone brightly day after day, and the Earth, a vibrant planet teeming with life. Every morning, Nimbus would gleefully catch the Sun's first rays, turning brilliant shades of orange, pink, and gold. As the day wore on, Nimbus would drift over the Earth's sprawling landscapes, from towering mountains and lush forests to arid deserts and bustling cities. The Earth cherished Nimbus, for he carried life-giving water, showering it upon the land when it was most needed. Together, the Cloud, the Sun, and the Earth lived in harmonious balance, each playing a vital role in the cycle of life.\n",
        "# Once in the celestial realms, where the horizon meets infinity, floated a wise cloud named Nimbus. This cloud was not just any cloud; Nimbus had seen centuries unfold below, witnessing the dance of the seasons across the Earth's face. Each day, Nimbus greeted the Sun, whose eternal flame ignited life beneath. The Sun's rays, a golden tapestry, wove through Nimbus, casting shadows and light across the lands. As Nimbus journeyed across the skies, it whispered to the rivers, mountains, and forests below, nurturing them with rain, orchestrating the symphony of nature.\n",
        "# There once was a cloud, Nimbus, who roamed the vast skies. Unlike any ordinary cloud, Nimbus harbored a secret: it could change shapes at will. This talent brought immense joy to the creatures of the Earth, who often looked up to find animals, trees, and even faces formed in the sky. The Sun, ever so generous, lent its splendid colors to Nimbus, painting the dawn and dusk with hues of reds and purples. Together, Nimbus and the Sun were the artists of the sky, creating masterpieces that spanned the horizon for all on Earth to see.\n",
        "# Far above the bustling life on Earth, Nimbus, a playful cloud, frolicked in the boundless sky. Each morning, Nimbus raced the Sun's rays to the edge of the world, bathing in their amber glow. The Earth below, a patchwork of greens and blues, flourished under their careful watch. Nimbus loved to shape itself into fluffy animals, delighting the children who gazed up from below. The Sun, with its gentle warmth, and Nimbus, with its cooling showers, balanced the world in harmony, ensuring the cycle of life continued unabated.\n",
        "# In the early hours before dawn, when the world whispered secrets, Nimbus, a curious cloud, hovered close to the Earth, listening intently. As the Sun peeked over the horizon, it filled Nimbus with a radiant glow, casting a soft light over the sleeping Earth. Nimbus, moved by the Earth's silent beauty, would then roam the skies, deciding where to bestow its life-giving bounty. The Sun's warmth coaxed the best out of Nimbus, allowing it to nourish the land below. Together, they worked in unison, a testament to the unwavering partnership between the sky and the ground.\n",
        "# As Nimbus floated over ancient cities and untouched wilds, it encountered another cloud, Zephyr, born of a distant storm and carrying tales of far-off lands. Together, they wandered the skies, sharing stories under the Sun's watchful gaze. One day, Zephyr spoke of a desert so vast that it seemed to swallow the horizon, a place where rain had not touched the earth for a century. Moved by the story, Nimbus decided it was time to embark on a new journey. With the Sun blessing their path, Nimbus and Zephyr set off to find this desert, determined to bring life back to its barren sands.\n",
        "# One evening, as Nimbus was painting the sunset, it noticed that the colors were not as bright as usual. The Sun seemed tired, its light dimming. Concerned, Nimbus approached the Sun, who shared that it felt its energy waning, a phenomenon that happened once every millennia for a short period. Understanding the importance of the Sun's vitality to the Earth, Nimbus pledged to help. It began gathering moisture more diligently than ever, creating a mirror-like surface on the Earth below to reflect the Sun's light, helping to conserve its energy. This act of solidarity reminded all of Earth's inhabitants of the interdependence among the elements.\n",
        "# After many seasons of harmony, Nimbus grew restless. It longed to explore beyond the familiar landscapes and the Sun's reach. One twilight, a comet streaked across the sky, igniting Nimbus's imagination with possibilities of the cosmos. With a heavy heart, Nimbus informed the Sun and the Earth of its desire to venture into the unknown. Supported by their blessings, Nimbus ascended, propelled by cosmic winds, leaving a trail of mist in its wake. As it journeyed through the stars, Nimbus discovered celestial wonders but also learned that no beauty was quite like that of its home, the Earth.\"\"\"\n",
        "# print(process_text(input_text)[\"result\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}